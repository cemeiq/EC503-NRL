\subsection{Matrix Factorization}
\subsubsection*{Multidimensional Scaling (MDS)}
Multidimensional Scaling (MDS) is a method for creating a Euclidean embedding of data for which one has distance / dissimilarity information. For instance, given an $N \times N$ matrix of distances between $N$ points, one can embed the points into $\mathbb{R}^k$ so as to preserve distance information. In particular, one can use MDS as a way to create useful features for graphs by considering the shortest path distance between vertices. MDS is similar to PCA, except instead of using correlation information, we make use of pointwise distances.

Classical Multidimensional Scaling works as follows: let $D$ be the dissimilarity matrix. Then:
\begin{enumerate}
  \item Let $D^{(2)}$ be the point-wise square of the distance matrix,
  \item Let $J = I - {1\over n}\vec{1}\vec{1}^T,
  \item Let B = -{1 \over 2}JD^{(2)}J,
  \item Find the top $m$ eigenvalues of $B$ $\lambda_1, ... \lambda_m$, and the corresponding eigenvalues $e_1, ... , e_m$,
  \item Let $X = E_m\Lambda^{1/2}$.
\end{enumerate}
(note to  self:doesn't work if distance not euclidean)


Classical Multidimensional Scaling minimizes a loss function called \emph{strain}:
\[
    Strain_D(x_1, ... , x_N) = \left( ({\sum_{i,j}b_{i,j}- \langle x_i,x_j \rangle})^2 \over \sum_{i,j}b_{i,j}^2\right)
\]


\subsubsection*{Isomap}
Isomap is a method for manifold learning / non-linear dimensionality reduction. In a general setting, given data points living in a (non-linear) manifold in \mathbb{R}^n we would like to embed them into lower dimensional space while preserving geodesic distances.
